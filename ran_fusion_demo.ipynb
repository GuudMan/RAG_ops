{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/langcha/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms.base import LLM\n",
    "from typing import Any, List, Optional\n",
    "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig, LlamaTokenizerFast\n",
    "import torch\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0, 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qwen2_LLM(LLM):\n",
    "    # 基于本地 Qwen2 自定义 LLM 类\n",
    "    tokenizer: AutoTokenizer = None\n",
    "    model: AutoModelForCausalLM = None\n",
    "        \n",
    "    def __init__(self, mode_name_or_path :str):\n",
    "\n",
    "        super().__init__()\n",
    "        print(\"正在从本地加载模型...\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(mode_name_or_path, use_fast=False)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(mode_name_or_path, torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "        self.model.generation_config = GenerationConfig.from_pretrained(mode_name_or_path)\n",
    "        print(\"完成本地模型的加载\")\n",
    "        \n",
    "    def _call(self, prompt : str, gene_multi_query:bool=False, stop: Optional[List[str]] = None,\n",
    "                run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "                **kwargs: Any):\n",
    "        if gene_multi_query:\n",
    "        # messages = [{\"role\": \"user\", \"content\": prompt }]\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": \"你是一个有用的助手， 可根据单个输入查询生成多个搜索查询。\"},\n",
    "                {\"role\": \"user\", \"content\": f\"根据这个提示： {prompt}生成多个搜索查询\"},\n",
    "                {\"role\": \"user\", \"content\": \"输出四个查询:\"}\n",
    "            ]\n",
    "        else:\n",
    "            messages = [{\"role\": \"user\", \"content\": prompt }]\n",
    "        input_ids = self.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "        model_inputs = self.tokenizer([input_ids], return_tensors=\"pt\").to('cuda')\n",
    "        generated_ids = self.model.generate(model_inputs.input_ids,max_new_tokens=768)\n",
    "        generated_ids = [\n",
    "            output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "        ]\n",
    "        response = self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "        return response\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"Qwen2_LLM\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在从本地加载模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完成本地模型的加载\n",
      "['1. \"ZUF-77-14-002 短信服务介绍\"', '2. \"关于号码ZUF-77-14-002的短信套餐详情\"', '3. \"ZUF-77-14-002短信功能解析\"', '4. \"如何订阅或使用ZUF-77-14-002的短信服务\"']\n"
     ]
    }
   ],
   "source": [
    "# from LLM import Qwen2_LLM\n",
    "llm = Qwen2_LLM(mode_name_or_path = \"/root/autodl-tmp/langchainqwen14b/model_local/qwen/Qwen1.5-7B-Chat\")\n",
    "response = llm(\"ZUF-77-14-002 短信业务具体是什么？\", gene_multi_query=True)\n",
    "generated_queries = response.strip().split(\"\\n\")\n",
    "print(generated_queries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# Mock function to simulate vector search, returning random scores\n",
    "def vector_search(query, all_documents):\n",
    "    available_docs = list(all_documents.keys())\n",
    "    random.shuffle(available_docs)\n",
    "    selected_docs = available_docs[:random.randint(2, 5)]\n",
    "    scores = {doc: round(random.uniform(0.7, 0.9), 2) for doc in selected_docs}\n",
    "    return {doc: score for doc, score in sorted(scores.items(), key=lambda x: x[1], reverse=True)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy function to simulate generative output\n",
    "def generate_output(reranked_results, queries):\n",
    "    return f\"Final output based on {queries} and reranked documents: {list(reranked_results.keys())}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 加载开源词向量模型\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"./embedding_model\")\n",
    "vectordb = Chroma(persist_directory='./data_base/vector_db/chroma', \n",
    "                   embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms.base import LLM\n",
    "from typing import Any, List, Optional\n",
    "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig, LlamaTokenizerFast\n",
    "import torch\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0, 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "# 我们所构造的 Prompt 模板\n",
    "template = \"\"\"使用以下上下文来回答最后的问题。如果你不知道答案，就说你不知道，不要试图编造答案。尽量使答案简明扼要。总是在回答的最后说“谢谢你的提问！”。\n",
    "{context}\n",
    "问题: {question}\n",
    "有用的回答:\"\"\"\n",
    "\n",
    "# 调用 LangChain 的方法来实例化一个 Template 对象，该对象包含了 context 和 question 两个变量，在实际调用时，这两个变量会被检索到的文档片段和用户提问填充\n",
    "QA_CHAIN_PROMPT = PromptTemplate(input_variables=[\"context\",\"question\"],\n",
    "                                 template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(llm,\n",
    "                                       retriever=vectordb.as_retriever(),\n",
    "                                       return_source_documents=True,\n",
    "                                       chain_type_kwargs={\"prompt\":QA_CHAIN_PROMPT})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_query = \"ZUF-77-14-002 短信业务具体是什么？\"\n",
    "response = llm(original_query, gene_multi_query=True)\n",
    "generated_queries = response.strip().split(\"\\n\")\n",
    "\n",
    "\n",
    "all_results = {}\n",
    "for query in generated_queries:\n",
    "    search_results = qa_chain({\"query\": query})\n",
    "    all_results[query] = search_results\n",
    "\n",
    "# print(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'str' and 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m query, doc_scores \u001b[38;5;129;01min\u001b[39;00m all_results\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m rank, doc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdoc_scores\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m):\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28mprint\u001b[39m(rank)\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28mprint\u001b[39m(doc)\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'list'"
     ]
    }
   ],
   "source": [
    "for query, doc_scores in all_results.items():\n",
    "    for rank, doc in enumerate(sorted(doc_scores.items(), key=lambda x: x[1], reverse=True)):\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reciprocal Rank Fusion algorithm\n",
    "def reciprocal_rank_fusion(search_results_dict, k=60):\n",
    "    fused_scores = {}\n",
    "    print(\"Initial individual search result ranks:\")\n",
    "    for query, doc_scores in search_results_dict.items():\n",
    "        print(f\"For query '{query}': {doc_scores}\")\n",
    "        \n",
    "    for query, doc_scores in search_results_dict.items():\n",
    "        for rank, (doc, score) in enumerate(sorted(doc_scores.items(), key=lambda x: x[1], reverse=True)):\n",
    "            if doc not in fused_scores:\n",
    "                fused_scores[doc] = 0\n",
    "            previous_score = fused_scores[doc]\n",
    "            fused_scores[doc] += 1 / (rank + k)\n",
    "            print(f\"Updating score for {doc} from {previous_score} to {fused_scores[doc]} based on rank {rank} in query '{query}'\")\n",
    "\n",
    "    reranked_results = {doc: score for doc, score in sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)}\n",
    "    print(\"Final reranked results:\", reranked_results)\n",
    "    return reranked_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial individual search result ranks:\n",
      "For query '1. \"ZUF-77-14-002 短信服务介绍\"': {'query': '1. \"ZUF-77-14-002 短信服务介绍\"', 'result': '\"ZUF-77-14-002描述了短信业务的实现原理和功能特性，但具体详细信息没有提供。\"', 'source_documents': [Document(page_content='ZUF\\n\\n78\\n\\n12\\n\\n006 eSRVCC', metadata={'source': './ops/zedx2txt/umac/ZUF-78-12 语音和短消息/142-ZUF-78-12-006 eSRVCC.txt'}), Document(page_content='ZUF-79-19-013 NL1/NLs\\n\\n描述\\n\\n实现原理\\n\\n遵循标准\\n\\nZUF-79-19-014 NL2/NLg\\n\\n描述\\n\\n实现原理\\n\\n遵循标准\\n\\nZUF-79-19-015 N17\\n\\n描述\\n\\n实现原理\\n\\n遵循标准\\n\\n缩略语\\n\\nAMF\\n\\nEBI\\n\\nEIR\\n\\nGMLC\\n\\nLMF\\n\\nLPP\\n\\nMME\\n\\nNSSF\\n\\nPCF\\n\\nSMF\\n\\nSMSF\\n\\nTA\\n\\nUDM\\n\\nUE', metadata={'source': './ops/zedx2txt/umac/ZUF-79-19 接口/index.txt'}), Document(page_content=\"ZUF\\n\\n76\\n\\n07 信令\\n\\n子主题：\\n\\nZUF\\n\\n76\\n\\n07\\n\\n001 M3UA\\n\\nZUF\\n\\n76\\n\\n07\\n\\n002 SCCP\\n\\nZUF\\n\\n76\\n\\n07\\n\\n003 MAP\\n\\nZUF\\n\\n76\\n\\n07\\n\\n004 TCAP\\n\\nZUF\\n\\n76\\n\\n07\\n\\n005 RANAP\\n\\nZUF\\n\\n76\\n\\n07\\n\\n006 BSSGP\\n\\nZUF\\n\\n76\\n\\n07\\n\\n007 BSSAP PLUS\\n\\nZUF\\n\\n76\\n\\n07\\n\\n008 GTP\\n\\nZUF\\n\\n76\\n\\n07\\n\\n009 S1AP\\n\\nZUF\\n\\n76\\n\\n07\\n\\n010 SGsAP\\n\\nZUF\\n\\n76\\n\\n07\\n\\n011 Diameter\\n\\nZUF\\n\\n76\\n\\n07\\n\\n012 GTP'\\n\\nZUF\\n\\n76\\n\\n07\\n\\n013 NGAP\", metadata={'source': './ops/zedx2txt/umac/nodes/ZUF-76-07 信令.txt'}), Document(page_content='概述\\n\\n功能描述\\n\\n功能特性简介\\n\\nZUF\\n\\n77\\n\\n14\\n\\n001 T\\n\\nADS功能\\n\\nZUF\\n\\n77\\n\\n14\\n\\n002 短信业务', metadata={'source': './ops/zedx2txt/umac/ZUF-77-14 语音与短信/index.txt'})]}\n",
      "For query '2. \"ZUF-77-14-002 短信套餐内容\"': {'query': '2. \"ZUF-77-14-002 短信套餐内容\"', 'result': '\"ZUF-77-14-002 是一个短信业务功能，提供了短信服务。\"', 'source_documents': [Document(page_content='概述\\n\\n功能描述\\n\\n功能特性简介\\n\\nZUF\\n\\n77\\n\\n14\\n\\n001 T\\n\\nADS功能\\n\\nZUF\\n\\n77\\n\\n14\\n\\n002 短信业务', metadata={'source': './ops/zedx2txt/umac/ZUF-77-14 语音与短信/index.txt'}), Document(page_content='ZUF\\n\\n77\\n\\n14 语音与短信\\n\\n子主题：\\n\\n概述\\n\\nZUF\\n\\n77\\n\\n14\\n\\n001 T\\n\\nADS功能\\n\\nZUF\\n\\n77\\n\\n14\\n\\n002 短信业务', metadata={'source': './ops/zedx2txt/umac/nodes/ZUF-77-14 语音与短信.txt'}), Document(page_content='ZUF\\n\\n79\\n\\n01 融合AMF&MME&SGSN\\n\\n子主题：\\n\\nZUF\\n\\n79\\n\\n01\\n\\n001 融合AMF&MME&SGSN', metadata={'source': './ops/zedx2txt/umac/nodes/ZUF-79-01 融合AMF&MME&SGSN.txt'}), Document(page_content='ZUF\\n\\n77\\n\\n12 计费\\n\\n子主题：\\n\\n概述\\n\\nZUF\\n\\n77\\n\\n12\\n\\n001 S\\n\\nCDR话单\\n\\nZUF\\n\\n77\\n\\n12\\n\\n002 M\\n\\nCDR话单\\n\\nZUF\\n\\n77\\n\\n12\\n\\n003 SMS\\n\\nCDR话单\\n\\nZUF\\n\\n77\\n\\n12\\n\\n004 LCS\\n\\nCDR话单\\n\\nZUF\\n\\n77\\n\\n12\\n\\n005 话单缓存', metadata={'source': './ops/zedx2txt/umac/nodes/ZUF-77-12 计费.txt'})]}\n",
      "For query '3. \"关于号码ZUF-77-14-002的短信功能说明\"': {'query': '3. \"关于号码ZUF-77-14-002的短信功能说明\"', 'result': '对不起，我无法提供特定号码ZUF-77-14-002的短信功能说明，因为我不具备实时查询个人电话服务详细信息的能力。请咨询相关的电信运营商或服务提供商以获取此类信息。谢谢你的提问！', 'source_documents': [Document(page_content='# 通用配置管理\\n\\n## 相关主题\\n\\n**网元管理\\n\\n**\\n\\n父主题：*\\n\\n配置管理', metadata={'source': './ops/zedx2txt/rcp/Npcf_PolicyManagement/zh-CN/tree/N_178718.txt'}), Document(page_content='# 分域配置\\n\\n## 相关主题\\n\\n**模式切换\\n\\n**\\n\\n**策略数据分域配置\\n\\n**\\n\\n父主题：*\\n\\n配置管理', metadata={'source': './ops/zedx2txt/rcp/Npcf_PolicyManagement/zh-CN/tree/N_178760.txt'}), Document(page_content='开通承载子切片\\n\\n子主题：\\n\\n配置承载子切片数据\\n\\n实例化承载子切片', metadata={'source': './ops/zedx2txt/umac/端到端切片解决方案/1603946133071.txt'}), Document(page_content='开通承载子切片\\n\\n子主题：\\n\\n配置承载子切片数据\\n\\n实例化承载子切片', metadata={'source': './ops/zedx2txt/rcp/端到端切片解决方案/1603946133071.txt'})]}\n",
      "For query '4. \"ZUF-77-14-002短信业务详细说明\"': {'query': '4. \"ZUF-77-14-002短信业务详细说明\"', 'result': '对不起，我不知道\"ZUF-77-14-002短信业务详细说明\"的具体内容。这个缩略语对应的描述或实现原理没有在您提供的信息中列出。', 'source_documents': [Document(page_content='ZUF-79-19-013 NL1/NLs\\n\\n描述\\n\\n实现原理\\n\\n遵循标准\\n\\nZUF-79-19-014 NL2/NLg\\n\\n描述\\n\\n实现原理\\n\\n遵循标准\\n\\nZUF-79-19-015 N17\\n\\n描述\\n\\n实现原理\\n\\n遵循标准\\n\\n缩略语\\n\\nAMF\\n\\nEBI\\n\\nEIR\\n\\nGMLC\\n\\nLMF\\n\\nLPP\\n\\nMME\\n\\nNSSF\\n\\nPCF\\n\\nSMF\\n\\nSMSF\\n\\nTA\\n\\nUDM\\n\\nUE', metadata={'source': './ops/zedx2txt/umac/ZUF-79-19 接口/index.txt'}), Document(page_content=\"ZUF\\n\\n76\\n\\n07 信令\\n\\n子主题：\\n\\nZUF\\n\\n76\\n\\n07\\n\\n001 M3UA\\n\\nZUF\\n\\n76\\n\\n07\\n\\n002 SCCP\\n\\nZUF\\n\\n76\\n\\n07\\n\\n003 MAP\\n\\nZUF\\n\\n76\\n\\n07\\n\\n004 TCAP\\n\\nZUF\\n\\n76\\n\\n07\\n\\n005 RANAP\\n\\nZUF\\n\\n76\\n\\n07\\n\\n006 BSSGP\\n\\nZUF\\n\\n76\\n\\n07\\n\\n007 BSSAP PLUS\\n\\nZUF\\n\\n76\\n\\n07\\n\\n008 GTP\\n\\nZUF\\n\\n76\\n\\n07\\n\\n009 S1AP\\n\\nZUF\\n\\n76\\n\\n07\\n\\n010 SGsAP\\n\\nZUF\\n\\n76\\n\\n07\\n\\n011 Diameter\\n\\nZUF\\n\\n76\\n\\n07\\n\\n012 GTP'\\n\\nZUF\\n\\n76\\n\\n07\\n\\n013 NGAP\", metadata={'source': './ops/zedx2txt/umac/nodes/ZUF-76-07 信令.txt'}), Document(page_content='# 通用配置管理\\n\\n## 相关主题\\n\\n**网元管理\\n\\n**\\n\\n父主题：*\\n\\n配置管理', metadata={'source': './ops/zedx2txt/rcp/Npcf_PolicyManagement/zh-CN/tree/N_178718.txt'}), Document(page_content=\".SE-KCEK 0050 4D 45 43 45 2D 5A 54 45 2D 31 1A 0C 00 00 0F 3E MECE-ZTE -1.....> 0060 FE 06 00 00 00 00 01 05 7A 74 65 1F 13 30 30 3A ........ zte..00: 0070 30 30 3A 30 30 3A 30 30 3A 30 30 3A 30 30 2D 06 00:00:00 :00:00-. 0080 00 00 00 01 05 06 00 00 00 00 3D 06 00 00 00 00 ........ ..=..... 0090 57 27 30 20 31 2F 32 2F 33 3A 38 38 2E 39 39 20 W'0 1/2/ 3:88.99 00A0 7A 74 65 2D 74 38 30 30 30 2F 30 2F 30 2F 30 2F zte-t800 0/0/0/0/ 00B0 30 2F 30 3A 30 2E 30 0/0:0.0 ZXR10 MPU-0/20/0 2013-5-13\", metadata={'source': './ops/zedx2txt/rcp/Rosng/安全/RADIUS配置命令/debug_radius_accounting_packet6205898A.txt'})]}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'str' and 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m reranked_results \u001b[38;5;241m=\u001b[39m \u001b[43mreciprocal_rank_fusion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_results\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 9\u001b[0m, in \u001b[0;36mreciprocal_rank_fusion\u001b[0;34m(search_results_dict, k)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor query \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdoc_scores\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m query, doc_scores \u001b[38;5;129;01min\u001b[39;00m search_results_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m rank, (doc, score) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28msorted\u001b[39m(doc_scores\u001b[38;5;241m.\u001b[39mitems(), key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m], reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)):\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m doc \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m fused_scores:\n\u001b[1;32m     11\u001b[0m             fused_scores[doc] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'list'"
     ]
    }
   ],
   "source": [
    "reranked_results = reciprocal_rank_fusion(all_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_output = generate_output(reranked_results, generated_queries)\n",
    "\n",
    "print(final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 下面是新的开始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# Multi Query: Different Perspectives\n",
    "template = \"\"\"You are an AI language model assistant. Your task is to generate five \n",
    "different versions of the given user question to retrieve relevant documents from a vector \n",
    "database. By generating multiple perspectives on the user question, your goal is to help\n",
    "the user overcome some of the limitations of the distance-based similarity search. \n",
    "Provide these alternative questions separated by newlines. Original question: {question}\"\"\"\n",
    "prompt_perspectives = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "generate_queries = (\n",
    "    prompt_perspectives \n",
    "    | StrOutputParser() \n",
    "    | (lambda x: x.split(\"\\n\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for Generation\ntext\n  str type expected (type=type_error.str)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is task decomposition for LLM agents?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     14\u001b[0m retrieval_chain \u001b[38;5;241m=\u001b[39m generate_queries \u001b[38;5;241m|\u001b[39m retriever\u001b[38;5;241m.\u001b[39mmap() \u001b[38;5;241m|\u001b[39m get_unique_union\n\u001b[0;32m---> 15\u001b[0m docs \u001b[38;5;241m=\u001b[39m \u001b[43mretrieval_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mlen\u001b[39m(docs)\n",
      "File \u001b[0;32m~/miniconda3/envs/langcha/lib/python3.11/site-packages/langchain_core/runnables/base.py:2053\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   2051\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2052\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[0;32m-> 2053\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2054\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# mark each step as a child run\u001b[39;49;00m\n\u001b[1;32m   2056\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2057\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2058\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2059\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2060\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   2061\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/langcha/lib/python3.11/site-packages/langchain_core/output_parsers/base.py:176\u001b[0m, in \u001b[0;36mBaseOutputParser.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[1;32m    168\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_result(\n\u001b[1;32m    169\u001b[0m             [ChatGeneration(message\u001b[38;5;241m=\u001b[39minner_input)]\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    173\u001b[0m         run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    174\u001b[0m     )\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/langcha/lib/python3.11/site-packages/langchain_core/runnables/base.py:1246\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1242\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[1;32m   1243\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(var_child_runnable_config\u001b[38;5;241m.\u001b[39mset, child_config)\n\u001b[1;32m   1244\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m   1245\u001b[0m         Output,\n\u001b[0;32m-> 1246\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1247\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1248\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1249\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1250\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1254\u001b[0m     )\n\u001b[1;32m   1255\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1256\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/miniconda3/envs/langcha/lib/python3.11/site-packages/langchain_core/runnables/config.py:326\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    325\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 326\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/langcha/lib/python3.11/site-packages/langchain_core/output_parsers/base.py:177\u001b[0m, in \u001b[0;36mBaseOutputParser.invoke.<locals>.<lambda>\u001b[0;34m(inner_input)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[1;32m    168\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_result(\n\u001b[1;32m    169\u001b[0m             [ChatGeneration(message\u001b[38;5;241m=\u001b[39minner_input)]\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    173\u001b[0m         run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    174\u001b[0m     )\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[0;32m--> 177\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_result([\u001b[43mGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m]),\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    179\u001b[0m         config,\n\u001b[1;32m    180\u001b[0m         run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    181\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/langcha/lib/python3.11/site-packages/langchain_core/load/serializable.py:107\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[0;32m~/miniconda3/envs/langcha/lib/python3.11/site-packages/pydantic/main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for Generation\ntext\n  str type expected (type=type_error.str)"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from langchain.load import dumps, loads\n",
    "\n",
    "def get_unique_union(documents: list[list]):\n",
    "    \"\"\" Unique union of retrieved docs \"\"\"\n",
    "    # Flatten list of lists, and convert each Document to string\n",
    "    flattened_docs = [dumps(doc) for sublist in documents for doc in sublist]\n",
    "    # Get unique documents\n",
    "    unique_docs = list(set(flattened_docs))\n",
    "    # Return\n",
    "    return [loads(doc) for doc in unique_docs]\n",
    "\n",
    "# Retrieve\n",
    "question = \"What is task decomposition for LLM agents?\"\n",
    "retrieval_chain = generate_queries | retriever.map() | get_unique_union\n",
    "docs = retrieval_chain.invoke({\"question\":question})\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langcha",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
